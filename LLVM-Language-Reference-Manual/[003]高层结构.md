# 高层结构
## 模块结构
LLVM programs are composed of Module’s, each of which is a translation unit of the input programs. Each module consists of functions, global variables, and symbol table entries. Modules may be combined together with the LLVM linker, which merges function (and global variable) definitions, resolves forward declarations, and merges symbol table entries. Here is an example of the “hello world” module:
```
; Declare the string constant as a global constant.
@.str = private unnamed_addr constant [13 x i8] c"hello world\0A\00"

; External declaration of the puts function
declare i32 @puts(i8* nocapture) nounwind

; Definition of main function
define i32 @main() {   ; i32()*
  ; Convert [13 x i8]* to i8*...
  %cast210 = getelementptr [13 x i8], [13 x i8]* @.str, i64 0, i64 0

  ; Call puts function to write out the string to stdout.
  call i32 @puts(i8* %cast210)
  ret i32 0
}

; Named metadata
!0 = !{i32 42, null, !"string"}
!foo = !{!0}
```
This example is made up of a global variable named “.str”, an external declaration of the “puts” function, a function definition for “main” and named metadata “foo”.

In general, a module is made up of a list of global values (where both functions and global variables are global values). Global values are represented by a pointer to a memory location (in this case, a pointer to an array of char, and a pointer to a function), and have one of the following linkage types.
## 连接类型
All Global Variables and Functions have one of the following types of linkage:

* private

    Global values with “private” linkage are only directly accessible by objects in the current module. In particular, linking code into a module with a private global value may cause the private to be renamed as necessary to avoid collisions. Because the symbol is private to the module, all references can be updated. This doesn’t show up in any symbol table in the object file.
* internal

    Similar to private, but the value shows as a local symbol (STB_LOCAL in the case of ELF) in the object file. This corresponds to the notion of the ‘static’ keyword in C.
* available_externally

    Globals with “available_externally” linkage are never emitted into the object file corresponding to the LLVM module. From the linker’s perspective, an available_externally global is equivalent to an external declaration. They exist to allow inlining and other optimizations to take place given knowledge of the definition of the global, which is known to be somewhere outside the module. Globals with available_externally linkage are allowed to be discarded at will, and allow inlining and other optimizations. This linkage type is only allowed on definitions, not declarations.
* linkonce

    Globals with “linkonce” linkage are merged with other globals of the same name when linkage occurs. This can be used to implement some forms of inline functions, templates, or other code which must be generated in each translation unit that uses it, but where the body may be overridden with a more definitive definition later. Unreferenced linkonce globals are allowed to be discarded. Note that linkonce linkage does not actually allow the optimizer to inline the body of this function into callers because it doesn’t know if this definition of the function is the definitive definition within the program or whether it will be overridden by a stronger definition. To enable inlining and other optimizations, use “linkonce_odr” linkage.
* weak

    “weak” linkage has the same merging semantics as linkonce linkage, except that unreferenced globals with weak linkage may not be discarded. This is used for globals that are declared “weak” in C source code.
* common

    “common” linkage is most similar to “weak” linkage, but they are used for tentative definitions in C, such as “int X;” at global scope. Symbols with “common” linkage are merged in the same way as weak symbols, and they may not be deleted if unreferenced. common symbols may not have an explicit section, must have a zero initializer, and may not be marked ‘constant’. Functions and aliases may not have common linkage.

* appending

    “appending” linkage may only be applied to global variables of pointer to array type. When two global variables with appending linkage are linked together, the two global arrays are appended together. This is the LLVM, typesafe, equivalent of having the system linker append together “sections” with identical names when .o files are linked.

    Unfortunately this doesn’t correspond to any feature in .o files, so it can only be used for variables like llvm.global_ctors which llvm interprets specially.

* extern_weak

    The semantics of this linkage follow the ELF object file model: the symbol is weak until linked, if not linked, the symbol becomes null instead of being an undefined reference.

* linkonce_odr, weak_odr

    Some languages allow differing globals to be merged, such as two functions with different semantics. Other languages, such as C++, ensure that only equivalent globals are ever merged (the “one definition rule” — “ODR”). Such languages can use the linkonce_odr and weak_odr linkage types to indicate that the global will only be merged with equivalent globals. These linkage types are otherwise the same as their non-odr versions.
* external

    If none of the above identifiers are used, the global is externally visible, meaning that it participates in linkage and can be used to resolve external symbol references.

It is illegal for a function declaration to have any linkage type other than external or extern_weak.

## 调用转换(Calling Convertions)
LLVM functions, calls and invokes can all have an optional calling convention specified for the call. The calling convention of any pair of dynamic caller/callee must match, or the behavior of the program is undefined. The following calling conventions are supported by LLVM, and more may be added in the future:

* “ccc” - The C calling convention

    This calling convention (the default if no other calling convention is specified) matches the target C calling conventions. This calling convention supports varargs function calls and tolerates some mismatch in the declared prototype and implemented declaration of the function (as does normal C).

* “fastcc” - The fast calling convention

    This calling convention attempts to make calls as fast as possible (e.g. by passing things in registers). This calling convention allows the target to use whatever tricks it wants to produce fast code for the target, without having to conform to an externally specified ABI (Application Binary Interface). Tail calls can only be optimized when this, the GHC or the HiPE convention is used. This calling convention does not support varargs and requires the prototype of all callees to exactly match the prototype of the function definition.

* “coldcc” - The cold calling convention


    This calling convention attempts to make code in the caller as efficient as possible under the assumption that the call is not commonly executed. As such, these calls often preserve all registers so that the call does not break any live ranges in the caller side. This calling convention does not support varargs and requires the prototype of all callees to exactly match the prototype of the function definition. Furthermore the inliner doesn’t consider such function calls for inlining.

* “cc 10” - GHC convention

    This calling convention has been implemented specifically for use by the Glasgow Haskell Compiler (GHC). It passes everything in registers, going to extremes to achieve this by disabling callee save registers. This calling convention should not be used lightly but only for specific situations such as an alternative to the register pinning performance technique often used when implementing functional programming languages. At the moment only X86 supports this convention and it has the following limitations:

        On X86-32 only supports up to 4 bit type parameters. No floating-point types are supported.
        On X86-64 only supports up to 10 bit type parameters and 6 floating-point parameters.

    This calling convention supports tail call optimization but requires both the caller and callee are using it.

* “cc 11” - The HiPE calling convention

    This calling convention has been implemented specifically for use by the High-Performance Erlang (HiPE) compiler, the native code compiler of the Ericsson’s Open Source Erlang/OTP system. It uses more registers for argument passing than the ordinary C calling convention and defines no callee-saved registers. The calling convention properly supports tail call optimization but requires that both the caller and the callee use it. It uses a register pinning mechanism, similar to GHC’s convention, for keeping frequently accessed runtime components pinned to specific hardware registers. At the moment only X86 supports this convention (both 32 and 64 bit).

* “webkit_jscc” - WebKit’s JavaScript calling convention

    This calling convention has been implemented for WebKit FTL JIT. It passes arguments on the stack right to left (as cdecl does), and returns a value in the platform’s customary return register.

* “anyregcc” - Dynamic calling convention for code patching

    This is a special convention that supports patching an arbitrary code sequence in place of a call site. This convention forces the call arguments into registers but allows them to be dynamically allocated. This can currently only be used with calls to llvm.experimental.patchpoint because only this intrinsic records the location of its arguments in a side table. See Stack maps and patch points in LLVM.

* “preserve_mostcc” - The PreserveMost calling convention

    This calling convention attempts to make the code in the caller as unintrusive as possible. This convention behaves identically to the C calling convention on how arguments and return values are passed, but it uses a different set of caller/callee-saved registers. This alleviates the burden of saving and recovering a large register set before and after the call in the caller. If the arguments are passed in callee-saved registers, then they will be preserved by the callee across the call. This doesn’t apply for values returned in callee-saved registers.

        On X86-64 the callee preserves all general purpose registers, except for R11. R11 can be used as a scratch register. Floating-point registers (XMMs/YMMs) are not preserved and need to be saved by the caller.

    The idea behind this convention is to support calls to runtime functions that have a hot path and a cold path. The hot path is usually a small piece of code that doesn’t use many registers. The cold path might need to call out to another function and therefore only needs to preserve the caller-saved registers, which haven’t already been saved by the caller. The PreserveMost calling convention is very similar to the cold calling convention in terms of caller/callee-saved registers, but they are used for different types of function calls. coldcc is for function calls that are rarely executed, whereas preserve_mostcc function calls are intended to be on the hot path and definitely executed a lot. Furthermore preserve_mostcc doesn’t prevent the inliner from inlining the function call.

    This calling convention will be used by a future version of the ObjectiveC runtime and should therefore still be considered experimental at this time. Although this convention was created to optimize certain runtime calls to the ObjectiveC runtime, it is not limited to this runtime and might be used by other runtimes in the future too. The current implementation only supports X86-64, but the intention is to support more architectures in the future.

* “preserve_allcc” - The PreserveAll calling convention

    This calling convention attempts to make the code in the caller even less intrusive than the PreserveMost calling convention. This calling convention also behaves identical to the C calling convention on how arguments and return values are passed, but it uses a different set of caller/callee-saved registers. This removes the burden of saving and recovering a large register set before and after the call in the caller. If the arguments are passed in callee-saved registers, then they will be preserved by the callee across the call. This doesn’t apply for values returned in callee-saved registers.

        On X86-64 the callee preserves all general purpose registers, except for R11. R11 can be used as a scratch register. Furthermore it also preserves all floating-point registers (XMMs/YMMs).

    The idea behind this convention is to support calls to runtime functions that don’t need to call out to any other functions.

    This calling convention, like the PreserveMost calling convention, will be used by a future version of the ObjectiveC runtime and should be considered experimental at this time.

* “cxx_fast_tlscc” - The CXX_FAST_TLS calling convention for access functions

    Clang generates an access function to access C++-style TLS. The access function generally has an entry block, an exit block and an initialization block that is run at the first time. The entry and exit blocks can access a few TLS IR variables, each access will be lowered to a platform-specific sequence.

    This calling convention aims to minimize overhead in the caller by preserving as many registers as possible (all the registers that are perserved on the fast path, composed of the entry and exit blocks).

    This calling convention behaves identical to the C calling convention on how arguments and return values are passed, but it uses a different set of caller/callee-saved registers.

    Given that each platform has its own lowering sequence, hence its own set of preserved registers, we can’t use the existing PreserveMost.

        On X86-64 the callee preserves all general purpose registers, except for RDI and RAX.

* “swiftcc” - This calling convention is used for Swift language.

        On X86-64 RCX and R8 are available for additional integer returns, and XMM2 and XMM3 are available for additional FP/vector returns.
        On iOS platforms, we use AAPCS-VFP calling convention.

* “cc <n>” - Numbered convention

    Any calling convention may be specified by number, allowing target-specific calling conventions to be used. Target specific calling conventions start at 64.

More calling conventions can be added/defined on an as-needed basis, to support Pascal conventions or any other well-known target-independent convention.

## Visibility Styles
所有全局变量和函数具有以下的可见性模式之一：

* “default” - Default style

  在那些使用ELF object file格式的平台（targets），默认可见性意味着声明对于其他模块是可见的，并且在可共享库，意味着这个声明的实体是可被覆盖的。在Darwin平台，默认可见性意味着声明对于其他模块是可见的。默认可见性与在这种语言中的 “external linkage” 是一致的。

* “hidden” - Hidden style

  一个对象的带有hidden可见性的两个声明，如果它们是处于一个相同的可共享单元（shared object），那么它们会被引用到一个相同的对象。通常来说，hidden可见性表明符号不会被放置到动态符号表，所以其他模块（可执行程序 或 共享库）不可以直接引用这个符号

* “protected” - Protected style

  在ELF中，protected 可见性表明符号会被放置到动态符号表，但在特定模块中的这些引用会绑定到一个本地的符号。所以这个符号不能被其他模块重写。
## DLL Storage Classes
所有全局变量，函数，别名（Aliases）可以拥有下面的DLL存储类别之一：

* dllimport

  “dllimport” 会导致编译器通过一个指向到 被DLL导出的指针 的全局指针，来引用一个函数或变量。在微软windows平台，这个指针名的格式为`__imp_`接上引用的函数或变量的名称（`__imp_`函数名）。
* dllexport

  “dllexport” 会导致编译器提供一个指向 一个在DLL中的指针 的全局变量，所以它可以被引用到带有 dllimport 属性的实体。在微软windows平台，这个指针名的格式为`__imp_ `接上引用的函数或变量的名称（`__imp_`函数名）。为了使编译器，汇编器和链接器知道某个符号是被外部引用并且防止这个符号被删除，因此这个存储类别为了定义一个dll接口而存在的。

## 线程本地存储模型(Thread Local Storage Models)
A variable may be defined as thread_local, which means that it will not be shared by threads (each thread will have a separated copy of the variable). Not all targets support thread-local variables. Optionally, a TLS model may be specified:

* localdynamic

    For variables that are only used within the current shared library.
* initialexec

    For variables in modules that will not be loaded dynamically.
* localexec

    For variables defined in the executable and only used within it.

If no explicit model is given, the “general dynamic” model is used.

The models correspond to the ELF TLS models; see ELF Handling For Thread-Local Storage for more information on under which circumstances the different models may be used. The target may choose a different TLS model if the specified model is not supported, or if a better choice of model can be made.

A model can also be specified in an alias, but then it only governs how the alias is accessed. It will not have any effect in the aliasee.

For platforms without linker support of ELF TLS model, the -femulated-tls flag can be used to generate GCC compatible emulated TLS code.

## Runtime Preemption Specifiers
Global variables, functions and aliases may have an optional runtime preemption specifier. If a preemption specifier isn’t given explicitly, then a symbol is assumed to be dso_preemptable.

* dso_preemptable

    Indicates that the function or variable may be replaced by a symbol from outside the linkage unit at runtime.

* dso_local

    The compiler may assume that a function or variable marked as dso_local will resolve to a symbol within the same linkage unit. Direct access will be generated even if the definition is not within this compilation unit.

## 结构类型
LLVM IR allows you to specify both “identified” and “literal” structure types. Literal types are uniqued structurally, but identified types are never uniqued. An opaque structural type can also be used to forward declare a type that is not yet available.

An example of an identified structure specification is:
```
%mytype = type { %mytype*, i32 }
```
Prior to the LLVM 3.0 release, identified types were structurally uniqued. Only literal types are uniqued in recent versions of LLVM.

## Non-Integral Pointer Type
Note: non-integral pointer types are a work in progress, and they should be considered experimental at this time.

LLVM IR optionally allows the frontend to denote pointers in certain address spaces as “non-integral” via the datalayout string. Non-integral pointer types represent pointers that have an unspecified bitwise representation; that is, the integral representation may be target dependent or unstable (not backed by a fixed integer).

inttoptr instructions converting integers to non-integral pointer types are ill-typed, and so are ptrtoint instructions converting values of non-integral pointer types to integers. Vector versions of said instructions are ill-typed as well.

## 全局变量
Global variables define regions of memory allocated at compilation time instead of run-time.

Global variable definitions must be initialized.

Global variables in other translation units can also be declared, in which case they don’t have an initializer.

Either global variable definitions or declarations may have an explicit section to be placed in and may have an optional explicit alignment specified. If there is a mismatch between the explicit or inferred section information for the variable declaration and its definition the resulting behavior is undefined.

A variable may be defined as a global constant, which indicates that the contents of the variable will never be modified (enabling better optimization, allowing the global data to be placed in the read-only section of an executable, etc). Note that variables that need runtime initialization cannot be marked constant as there is a store to the variable.

LLVM explicitly allows declarations of global variables to be marked constant, even if the final definition of the global is not. This capability can be used to enable slightly better optimization of the program, but requires the language definition to guarantee that optimizations based on the ‘constantness’ are valid for the translation units that do not include the definition.

As SSA values, global variables define pointer values that are in scope (i.e. they dominate) all basic blocks in the program. Global variables always define a pointer to their “content” type because they describe a region of memory, and all memory objects in LLVM are accessed through pointers.

Global variables can be marked with unnamed_addr which indicates that the address is not significant, only the content. Constants marked like this can be merged with other constants if they have the same initializer. Note that a constant with significant address can be merged with a unnamed_addr constant, the result being a constant whose address is significant.

If the local_unnamed_addr attribute is given, the address is known to not be significant within the module.

A global variable may be declared to reside in a target-specific numbered address space. For targets that support them, address spaces may affect how optimizations are performed and/or what target instructions are used to access the variable. The default address space is zero. The address space qualifier must precede any other attributes.

LLVM allows an explicit section to be specified for globals. If the target supports it, it will emit globals to the section specified. Additionally, the global can placed in a comdat if the target has the necessary support.

External declarations may have an explicit section specified. Section information is retained in LLVM IR for targets that make use of this information. Attaching section information to an external declaration is an assertion that its definition is located in the specified section. If the definition is located in a different section, the behavior is undefined.

By default, global initializers are optimized by assuming that global variables defined within the module are not modified from their initial values before the start of the global initializer. This is true even for variables potentially accessible from outside the module, including those with external linkage or appearing in @llvm.used or dllexported variables. This assumption may be suppressed by marking the variable with externally_initialized.

An explicit alignment may be specified for a global, which must be a power of 2. If not present, or if the alignment is set to zero, the alignment of the global is set by the target to whatever it feels convenient. If an explicit alignment is specified, the global is forced to have exactly that alignment. Targets and optimizers are not allowed to over-align the global if the global has an assigned section. In this case, the extra alignment could be observable: for example, code could assume that the globals are densely packed in their section and try to iterate over them as an array, alignment padding would break this iteration. The maximum alignment is 1 << 29.

Globals can also have a DLL storage class, an optional runtime preemption specifier, an optional global attributes and an optional list of attached metadata.

Variables and aliases can have a Thread Local Storage Model.

Syntax:
```
@<GlobalVarName> = [Linkage] [PreemptionSpecifier] [Visibility]
                   [DLLStorageClass] [ThreadLocal]
                   [(unnamed_addr|local_unnamed_addr)] [AddrSpace]
                   [ExternallyInitialized]
                   <global | constant> <Type> [<InitializerConstant>]
                   [, section "name"] [, comdat [($name)]]
                   [, align <Alignment>] (, !name !N)*
```
For example, the following defines a global in a numbered address space with an initializer, section, and alignment:
```
@G = addrspace(5) constant float 1.0, section "foo", align 4
```
The following example just declares a global variable
```
@G = external global i32
```
The following example defines a thread-local global with the initialexec TLS model:
```
@G = thread_local(initialexec) global i32 0, align 4
```
## 函数
LLVM函数定义由“define” 关键字，一个可选的链接标识，一个可选的可见性模式，一个可选的DLL存储类别，一个可选的调用约定，一个可选的 unnamed_addr 属性，一个返回值类型，一个可选的返回值的参数属性，一个函数名，一个（可能为空的）实参列表（每一个都带有可选的参数属性），可选的函数属性，一个可选的section，一个可选的对齐属性，一个可选垃圾回收期的名字，一个可选的前缀，一个左花括号，一个基本块列表和一个右花括号。

LLVM函数声明由 “declare” 关键字，一个可选的链接标识，一个可选的可见性模式，一个可选的DLL存储类型，一个可选的调用约定，一个可选的 unnamed_addr 属性，一个返回值类型，一个可选的返回值类型的参数属性，一个函数名，一个可能为空的实参列表，一个可选对齐属性，一个可选垃圾回收器名和一个可选的前缀。

一个函数定义包含一个基本块的列表，可以为函数形成CFG（控制流图形）。每一个基本块可以（可选的）开始于一个label（给定这个基本快一个符号表入口），包含一个指令列表，并且结束与一个终止指令（例如分支或函数返回）。如果一个明确的label不被提供，一个快会被分配到一个隐式的编号label，使用的计数器与匿名临时变量使用同一个计数器。例如，如果一个函数入口块不具有一个显示的label，他会被分配到一个label "%0"，然后第一个在这个块中的匿名临时变量将会是“%1”。

函数中的第一基本块特殊在两个方面: 她是在函数进入后马上执行的，并且它是不允许有前置基本块(即函数入口块不能拥有任何分支)。因为这个块没有前置块，所以也不能有任何 PHI nodes.

LLVM允许函数指定一个明确的section。如果目标平台支持它，它会放散函数到这个指定块。

一个显示的对齐属性可能会被指定到一个函数。如果没有指定，或者对齐属性被设置为0，那么这个函数的对齐属性将会根据目标平台的需要设定。如果一个显式对齐属性被指定，这个函数被迫至少想指定的那么多对齐。所有对齐属性必须为2的次幂。

如果 unnamed_addr 属性被指定了，函数的地址会被认为是不重要的且两个相同的函数之间可以被合并。

语法:
```
define [linkage] [visibility] [DLLStorageClass]
       [cconv] [ret attrs]
       <ResultType> @<FunctionName> ([argument list])
       [fn Attrs] [section "name"] [align N]
       [gc] [prefix Constant] { ... }
```
## 别名
Aliases, unlike function or variables, don’t create any new data. They are just a new symbol and metadata for an existing position.

Aliases have a name and an aliasee that is either a global value or a constant expression.

Aliases may have an optional linkage type, an optional runtime preemption specifier, an optional visibility style, an optional DLL storage class and an optional tls model.

Syntax:
```
@<Name> = [Linkage] [PreemptionSpecifier] [Visibility] [DLLStorageClass] [ThreadLocal] [(unnamed_addr|local_unnamed_addr)] alias <AliaseeTy>, <AliaseeTy>* @<Aliasee>
```
The linkage must be one of private, internal, linkonce, weak, linkonce_odr, weak_odr, external. Note that some system linkers might not correctly handle dropping a weak symbol that is aliased.

Aliases that are not unnamed_addr are guaranteed to have the same address as the aliasee expression. unnamed_addr ones are only guaranteed to point to the same content.

If the local_unnamed_addr attribute is given, the address is known to not be significant within the module.

Since aliases are only a second name, some restrictions apply, of which some can only be checked when producing an object file:

* The expression defining the aliasee must be computable at assembly time. Since it is just a name, no relocations can be used.

* No alias in the expression can be weak as the possibility of the intermediate alias being overridden cannot be represented in an object file

* No global value in the expression can be a declaration, since that would require a relocation, which is not possible.

## IFuncs
IFuncs, like as aliases, don’t create any new data or func. They are just a new symbol that dynamic linker resolves at runtime by calling a resolver function.

IFuncs have a name and a resolver that is a function called by dynamic linker that returns address of another function associated with the name.

IFunc may have an optional linkage type and an optional visibility style.

Syntax:
```
@<Name> = [Linkage] [Visibility] ifunc <IFuncTy>, <ResolverTy>* @<Resolver>
```


## Comdats
Comdat IR provides access to COFF and ELF object file COMDAT functionality.

Comdats have a name which represents the COMDAT key. All global objects that specify this key will only end up in the final object file if the linker chooses that key over some other key. Aliases are placed in the same COMDAT that their aliasee computes to, if any.

Comdats have a selection kind to provide input on how the linker should choose between keys in two different object files.

Syntax:
```
$<Name> = comdat SelectionKind
```

The selection kind must be one of the following:

* any

    The linker may choose any COMDAT key, the choice is arbitrary.

* exactmatch

    The linker may choose any COMDAT key but the sections must contain the same data.

* largest

    The linker will choose the section containing the largest COMDAT key.

* noduplicates

    The linker requires that only section with this COMDAT key exist.

* samesize

    The linker may choose any COMDAT key but the sections must contain the same amount of data.

Note that the Mach-O platform doesn’t support COMDATs, and ELF and WebAssembly only support any as a selection kind.

Here is an example of a COMDAT group where a function will only be selected if the COMDAT key’s section is the largest:
```
$foo = comdat largest
@foo = global i32 2, comdat($foo)

define void @bar() comdat($foo) {
  ret void
}
```
As a syntactic sugar the $name can be omitted if the name is the same as the global name:
```
$foo = comdat any
@foo = global i32 2, comdat
```
In a COFF object file, this will create a COMDAT section with selection kind IMAGE_COMDAT_SELECT_LARGEST containing the contents of the @foo symbol and another COMDAT section with selection kind IMAGE_COMDAT_SELECT_ASSOCIATIVE which is associated with the first COMDAT section and contains the contents of the @bar symbol.

There are some restrictions on the properties of the global object. It, or an alias to it, must have the same name as the COMDAT group when targeting COFF. The contents and size of this object may be used during link-time to determine which COMDAT groups get selected depending on the selection kind. Because the name of the object must match the name of the COMDAT group, the linkage of the global object must not be local; local symbols can get renamed if a collision occurs in the symbol table.

The combined use of COMDATS and section attributes may yield surprising results. For example:
```
$foo = comdat any
$bar = comdat any
@g1 = global i32 42, section "sec", comdat($foo)
@g2 = global i32 42, section "sec", comdat($bar)
```
From the object file perspective, this requires the creation of two sections with the same name. This is necessary because both globals belong to different COMDAT groups and COMDATs, at the object file level, are represented by sections.

Note that certain IR constructs like global variables and functions may create COMDATs in the object file in addition to any which are specified using COMDAT IR. This arises when the code generator is configured to emit globals in individual sections (e.g. when -data-sections or -function-sections is supplied to llc).

## 具名元数据(Named Metadata)
Named metadata is a collection of metadata. Metadata nodes (but not metadata strings) are the only valid operands for a named metadata.

    Named metadata are represented as a string of characters with the metadata prefix. The rules for metadata names are the same as for identifiers, but quoted names are not allowed. "\xx" type escapes are still valid, which allows any character to be part of a name.

Syntax:
```
; Some unnamed metadata nodes, which are referenced by the named metadata.
!0 = !{!"zero"}
!1 = !{!"one"}
!2 = !{!"two"}
; A named metadata.
!name = !{!0, !1, !2}
```

## 参数属性(Parameter Attributes)
这个返回类型和每一个函数的参数类型可能拥有一个参数属性集。参数属性是用于交流函数的返回值和参数的额外信息。参数类型被认为是函数的一部分，但不是函数类型的一部分，所以用不同的参数属性的函数可以拥有同一个函数类型。

参数属性是是以下的一些跟在类型后的简单的关键字。如果需要多个参数属性，他们需要被空白符分隔开。

例如:
```
declare i32 @printf(i8* noalias nocapture, ...)
declare i32 @atoi(i8 zeroext)
declare signext i8 @returns_signed_char()
```
注意，任何对于函数结果nounwind, readonly)属性跟随在实参列表后。

当前，仅有以下的参数属性被定义：

* zeroext

  这表明了在代码生成时，参数或返回值应该被0扩展到目标平台ABI要求调用者（即参数长度）和被调用者（即返回值长度）的长度范围（一般来说是32bits，但对于x86-64的i1来说是8bits）。Note：是因为寄存器大小和要求压栈操作数大小？

* signext

  这表明了代码生成时，参数或返回值应该被符号扩展到目标平台ABI要求调用者（即参数长度）和被调用者（即返回值长度）的长度范围（一般来说是32bits）。Note：对于有符号数即需要符号位扩展

* inreg

  这表明参数和返回值在发散函数调用或返回值的期间，需要应该以一个依赖于特定平台的样式对待（通常来说，把参数和返回值放置到寄存器而不是放置到存储器中，即使一些目标平台使用它来区分两种不同的寄存器）。这个属性的使用的针对指定平台的。

* byval

  这表明指针参数应该已传至方式传递到函数中。这个属性蕴含了在调用者和被调用者之间的一个隐藏的指针复制操作，因此使被调用者不能修改在调用者里的值。这个属性仅在LLVM指针实参里是有效的。这通常用于传递结构体和数组的值（寄存器只能存放这届数据的指针），但这对于scalar object的指针也是有效的。

  这个复制被认为是从属于调用者而不是被调用者的（例如，readonly 函数不应该写一个 byval 的参数）。这个属性对于返回值是无效的。

  这个 byval 属性同样支持指定对齐属性。这指明了stack slot的对齐格式且指定调用地点的指针对齐属性。如果对齐属性不被指定的话，代码生成器会做一个平台相关的猜测。

* inalloca

  注意

  这个特性是不稳定的且没有完全实现。

  inalloca 实参属性允许调用者带有即将离开stack的实参地址。一个 inalloca 实参必须是一个使用 alloca 指令创建指向栈内存的指针的地址。这个分配的堆栈空间或实参分配必须也以inalloca关键字标识。只有过去的实参可以使用inalloca属性且这个实参保证在内存中传递。

  一个实参分配可能被函数调用使用至少一次因为这个函数调用可能会释放它。这个 inalloca 属性不可能与其他会影响实参存储的属性结合使用，像inreg, nest, sret, or byval。这个 inalloca 属性也禁止LLVM隐式降低大型聚合返回值，这意味着前端作者必须通过 sret 降低他们。

  当到达调用地点时，实参分配必须是仍然活的最新栈分配，或者结果是未定义的。在一个实参分配后和这个实参的调用地点前额外分配堆栈空间是可能的，但这必须清除llvm.stackrestore。

  详见 Design and Usage of the InAlloca Attribute

* sret

  这表明这个指针参数指向一个在源程序中作为函数返回值的结构体的地址。这个指针必须由调用者保证是有效的：这个结构的加载和存储必须与被调用者所假定的方式是一致的。这只适用于第一个参数。这对于返回值并不是一个有效的属性。

* noalias

  这表明基于实参或者返回值的指针值不是一个不基于它们的别名指针值，忽略明确的“irrelevant”依赖。对于一个父函数的调用，在函数调用前后的内存引用和函数调用内部的内存引用之间的依赖对于带有 noalias 关键字的实参和返回值是“irrelevant”。这个调用者与被调用者共享这个关系以确定这些要求得到满足。更多的细节，请查看alias analysis中的noalias响应的讨论。
  注意 noalias 的定义故意定义得与C99中的函数实参的 restrict 定义相似，尽管 restrict 的定义稍微弱一些。
  因为对于函数返回至，C99的 restrict 是无意义的而LLVM的 noalias 是有意义的。

* nocapture

  这表明被调用者不对生存期比被调用者长的指针做出任何复制。对于返回值这不是一个有效的属性。

* nest

  这表明指针参数可以使用trampoline intrinsics删除。这不是一个有效的返回值属性，只能被应用于一个参数。
* returned

  这表明函数始终返回这个参数作为它的返回值。代码生成器生成调用者时的一个优化提示，允许尾部调用优化和在某种情况下忽略寄存器的保存和恢复；在省城被调用者是，它不会被检查或执行。参数和函数返回类型必须是对于bitcast指令有效的操作数。这不是一个有效的返回值属性,只能应用于一个参数。

* nonnull

    This indicates that the parameter or return pointer is not null. This attribute may only be applied to pointer typed parameters. This is not checked or enforced by LLVM; if the parameter or return pointer is null, the behavior is undefined.

* dereferenceable(<n>)

    This indicates that the parameter or return pointer is dereferenceable. This attribute may only be applied to pointer typed parameters. A pointer that is dereferenceable can be loaded from speculatively without a risk of trapping. The number of bytes known to be dereferenceable must be provided in parentheses. It is legal for the number of bytes to be less than the size of the pointee type. The nonnull attribute does not imply dereferenceability (consider a pointer to one element past the end of an array), however dereferenceable(<n>) does imply nonnull in addrspace(0) (which is the default address space).

* dereferenceable_or_null(<n>)

    This indicates that the parameter or return value isn’t both non-null and non-dereferenceable (up to <n> bytes) at the same time. All non-null pointers tagged with dereferenceable_or_null(<n>) are dereferenceable(<n>). For address space 0 dereferenceable_or_null(<n>) implies that a pointer is exactly one of dereferenceable(<n>) or null, and in other address spaces dereferenceable_or_null(<n>) implies that a pointer is at least one of dereferenceable(<n>) or null (i.e. it may be both null and dereferenceable(<n>)). This attribute may only be applied to pointer typed parameters.

* swiftself

    This indicates that the parameter is the self/context parameter. This is not a valid attribute for return values and can only be applied to one parameter.

* swifterror

    This attribute is motivated to model and optimize Swift error handling. It can be applied to a parameter with pointer to pointer type or a pointer-sized alloca. At the call site, the actual argument that corresponds to a swifterror parameter has to come from a swifterror alloca or the swifterror parameter of the caller. A swifterror value (either the parameter or the alloca) can only be loaded and stored from, or used as a swifterror argument. This is not a valid attribute for return values and can only be applied to one parameter.

    These constraints allow the calling convention to optimize access to swifterror variables by associating them with a specific register at call boundaries rather than placing them in memory. Since this does change the calling convention, a function which uses the swifterror attribute on a parameter is not ABI-compatible with one which does not.

    These constraints also allow LLVM to assume that a swifterror argument does not alias any other memory visible within a function and that a swifterror alloca passed as an argument does not escape.

* immarg

    This indicates the parameter is required to be an immediate value. This must be a trivial immediate integer or floating-point constant. Undef or constant expressions are not valid. This is only valid on intrinsic declarations and cannot be applied to a call site or arbitrary function.

## 垃圾回收器名
每一个函数可以制定一个垃圾回收期的名称，这个名称是一个简单的字符串：
```
define void @f() gc "name" { ... }
```
编译器声明了这个名字的可能值。指定一个收集器将会导致编译器会为了支持这个垃圾回收算法修改它的输出。

## 前置数据（Prefix Data）
前置数据是一种与函数相关的数据，在函数主体之前代码生成器会马上发散这种数据。这个特性的目的是为了让允许在前端分配语言指定的在指定函数中运行期元数据，并且可以通过函数指针来获得这个数据的同时这个函数指针仍然是可调用的。对一个给定的函数来访问这个数据，程序可以通过bitcast转换这个函数指针到一个常量类型的指针。这是意味着这个IR符号指向这个前置数据的开始。

为了维持普通函数调用的语义，这个前置数据必须有一个实际格式。具体来说，这必须开始于一段bytes序列，且可以从中解码到一段用于该模块目标的机器指令序列，这个点的传送控制紧随这个前缀数据，而不执行任何其他的可见动作。这就允许内联器和其他pass来推论这是一个函数定义语义而不是需要一个前置数据。显而易见地，这使前置数据的格式高度依赖于目标平台。

前置数据的定义，类似于一个前缀数据类型的全局变量的初始化式。在前置数据和函数主体之间没有自动填充的数据。如果有填充要求，那么它必须是前置数据的一部分。

这是一个很小的有效前置数据，其对于X86体系结构的值为144，类型为i8，则会被编码为 nop 指令。
```
define void @f() prefix i8 144 { ... }
```
一般来说，前置数据可以跳过元数据通过编码一个相关的branch指令，就像下面这个例子中的对于X86_64体系有效的前置数据，它的前两个byte将被编码jmp.+10

```
%0 = type <{ i8, i8, i8* }>

define void @f() prefix %0 <{ i8 235, i8 8, i8* @md}> { ... }
```
函数可能只拥有前置数据但没有主体。这与 available_externally 链接标识有着相同的语义，即数据可能会被优化器使用的不会被发散到对象文件中。
## Prologue Data
The prologue attribute allows arbitrary code (encoded as bytes) to be inserted prior to the function body. This can be used for enabling function hot-patching and instrumentation.

To maintain the semantics of ordinary function calls, the prologue data must have a particular format. Specifically, it must begin with a sequence of bytes which decode to a sequence of machine instructions, valid for the module’s target, which transfer control to the point immediately succeeding the prologue data, without performing any other visible action. This allows the inliner and other passes to reason about the semantics of the function definition without needing to reason about the prologue data. Obviously this makes the format of the prologue data highly target dependent.

A trivial example of valid prologue data for the x86 architecture is i8 144, which encodes the nop instruction:

```
define void @f() prologue i8 144 { ... }
```
Generally prologue data can be formed by encoding a relative branch instruction which skips the metadata, as in this example of valid prologue data for the x86_64 architecture, where the first two bytes encode jmp .+10:
```
%0 = type <{ i8, i8, i8* }>

define void @f() prologue %0 <{ i8 235, i8 8, i8* @md}> { ... }
```
A function may have prologue data but no body. This has similar semantics to the available_externally linkage in that the data may be used by the optimizers but will not be emitted in the object file.

## 私有函数（Personality Function）
The personality attribute permits functions to specify what function to use for exception handling.

## 属性组
属性组是在IR中的对象引用的属性的集合。他们对于保持 .ll 可读有着重要意义，因为许都函数会使用相同的属性集。在退化的情况下一个 .ll 文件对应着单一的 .c 文件，这个单一的属性组讲捕获那些用于构建这个文件的重要命令行标识。

一个属性组是一个模块层次的对象。要使用一个属性组，一个对象可以引用这个属性组的ID（例如 #37）。一个对象可能引用超过一个属性组。在这种情况下来自于不同属性组的属性会被合并。

这里有一个规定一个函数应该内联的属性组的例子，并拥有一个堆栈对齐属性值为4，且不使用SSE指令
```
; Target-independent attributes:
attributes #0 = { alwaysinline alignstack=4 }

; Target-dependent attributes:
attributes #1 = { "no-sse" }

; Function @f has attributes: alwaysinline, alignstack=4, and "no-sse".
define void @f() #0 #1 { ... }
```

## 函数属性（Function Attributes）
函数属性用于函数交流额外信息的。函数属性被认为是函数的一部分，而不是函数类型的一部分，所以拥有不同函数属性的函数可以对应着同一个函数类型。

函数属性是紧跟在指定的函数类型后的简单的关键字。如果以后需要指定多个函数属性，那么使用空格符分隔它们。例如：
```
define void @f() noinline { ... }
define void @f() alwaysinline { ... }
define void @f() alwaysinline optsize { ... }
define void @f() optsize { ... }
```

* alignstack(<n>)

  这个属性指明了，当发散序言和后记，后端应该强制对齐堆栈指针。在括号中指定所希望的对齐属性，其值必须是2的幂。
* alwaysinline

  该属性指明了内联器应该尽可能地内联这个函数到调用者中，而忽略这个调用者有效的内联阙值。
* builtin

  这表明，在调用点被调用函数应该被认定为内建函数，即使该函数的声明使用了 nobuiltin 属性。这只在直接调用了声明了 nobuiltin 属性的函数的调用地点有效。
* cold

  该属性表明了这个函数将很少被调用。在计算边权重时，被一个cold函数所控制的基本块也被认为是cold的，因此将被给予低权重。
* inlinehint

  该属性表明，这份源代码包含一个提示，即内联函数是可行的（如C / C + +中的“inline”关键字）。这仅仅是一个提示，它不对内联器做出任何要求。
* minsize

  该属性建议优化器pass和代码生成器pass保持函数的代码长度尽量的小且牺牲运行时效率来最小化生成的代码来进行优化。
* naked

  这个属性禁止函数的序言/结尾发散。产生的结果是特定于系统的。
* nobuiltin

  这表明，在调用点被调用函数不被识别为一个内建函数。 LLVM将保留原来的调用，而不是使用基于内建函数语义等价的代码替换它，除非调用点使用了 builtin 的属性。这个属性对于调用点和函数的声明和定义都是有效的。、
* noduplicate

  该属性表明，函数的调用不能被复制。一个 noduplicate 函数的调用可能被移动到父函数​​，但不能被复制到父函数。

  一个包含 noduplicate 函数仍然可能被内联，条件是该调用没有被重复内联。这意味着，该函数具有 internal 链接标识，并只有一个调用点，所以内联后，原始调用被删除。

* noimplicitfloat

  该属性表明，禁用隐式的浮点指令
* noinline

  此属性表明，在任何情况下，内联器都不应该内联该函数。此属性不能与alwaysinline 属性一起使用。
* nonlazybind

  此属性表明，抑制函数的延迟绑定符号特性。如果函数在程序启动时不被调用，那么程序启动会耗费额外的启动时间，但这可能会使函数调用更快。
* noredzone

  此属性表明，即使目标平台指定的ABI通常允许，该属性指示代码生成器也不应该使用一个red zone，。
* noreturn

  此属性表明，该函数从不正常返回。如果该函数动态返回，这将产生不确定的运行期行为，。
* nounwind

  此属性表明，该函数从不返回展开的或异常的控制流。如果函数不展开，其运行时的行为是未定义的。
* optnone

  此此属性表明，该函数不能被除了过程间优化 pass 外的任何优化或代码生成器 pass 优化。这个属性不能与一起 alwaysinline 属性使用；这个属性也与 minsize 属性和 optsize 属性不兼容。（ minsize 与 optsize 要求优化）

  此属性要求在函数中同时指定该属性和 noinline 属性，所以该函数从不内联到任何调用者。只有具备alwaysinline 属性的函数才能内联到这个函数。

* optsize

  此属性表明，优化 pass 和代码生成器 pass 应该保持这个函数的代码长度较小，否则进行特定的优化，不显著影响运行期性能的情况下减少代码长度。
* readnone

    对于一个函数，这个属性表明该函数严格基于它的参数计算其结果（或决定展开异常），而不通过解引用任何指针参数或以其他方式访问任何调用者可见的可变状态（如内存，控制寄存器等）。它不通过任何指针参数（包括 byval 参数）写入和从不改变调用者可见的任何状态。这意味着它无法通过调用C + +的异常throw的方法展开异常。

    对于一个参数，这个属性表明，该函数不能解引用指针参数，尽管如果通过其他指针它可以读取或写入指针参数指向内存（因为调用者可见的是指针的值而不是指针指向的值）。
* readonly

  对于一个函数，这个属性表明该函数不通过任何指针参数（包括 byval 参数）或写其他方式修改任何调用者函数可见的状态（如内存，控制寄存器等）。它可能会解引用指针参数和读取在调用者中设置的状态。在使用相同的函数集和全局状态时，一个只读函数总是返回相同的值（或展开相同的异常）。它无法通过调用C + +的异常throw的方法展开异常。

  上一个参数，这个属性表示该函数不通过这个指针参数写的，即使它可能写入内存的指针指向。

* returns_twice

  该属性表明，该函数可以返回两次。该C setjmp 的是这样一种函数的一个例子。编译器禁用这些函数的调用者一些优化（如尾调用）。
* sanitize_address

  该属性表明，为函数启用AddressSanitizer检查（动态地址安全分析）。
* sanitize_memory

    该属性表明，为函数启用MemorySanitizer检查（未初始化内存访问的动态检测）
* sanitize_thread

    该属性表明，为函数启用ThreadSanitizer检查（动态线程安全性分析）
* ssp

  该属性表明，该函数应该发散一个堆栈溢出保护功能。它有一个“canary”形式 —（ a random value placed on the stack before the local variables that’s checked upon return from the function to see if it has been overwritten.）。一个启发式用来确定一个函数需要的堆栈保护与否。在以下情况，这个被使用了启发式将启用函数保护器：

  字符数组比 ssp-buffer-size 大（默认值为8）。
  字符数组的集合比 ssp-buffer-size 大。
  调用alloca（）的变量长度或常量长度（alloca的参数）大于 ssp-buffer-size 。

  被识别为需要保护的变量将被安排在堆栈，使得对于堆栈保护器它们是连续的。

  如果一个函数，它有一个SSP属性被内联到一个不具有SSP属性的函数，然后将得到的函数将具有一个SSP属性。

* sspreq

  该属性表明，该函数应该发散一个堆栈溢出保护功能。这将覆盖 ssp 函数属性。

  被识别为需要保护的变量将被安排在堆栈，使得对于堆栈保护器它们是连续的。具体布局规则是：

  * 大数组和含大数组的结构体（>= sp-buffer-size）是最接近堆栈保护器的。
  * 小数组和含小数组的结构体（< sp-buffer-size）是第二接近堆栈保护器的。
  * 采取了它们的地址的变量是第三接近堆栈保护器的。

  如果一个函数，它有一个 sspreq 属性被内联到一个不具有 sspreq 属性或具有 ssp 或 sspstrong 属性的函数，那么得到的结果函数将具有 sspreq 属性。
* sspstrong

  该属性表明，该函数应该发散一个堆栈溢出保护功能。在确定函数是否需要的堆栈保护器时，此属性会使用一个强有力的试探法。强大的启发式将为函数启用保护器：

    * 任何长度和类型的数组
    * 任何长度和类型的数组的集合。
    * 调用了alloca（ ） 。
    * 采取了它们的地址的局部变量。

  被识别为需要保护的变量将被安排在堆栈，使得对于堆栈保护器它们是连续的。具体布局规则是：

    * 大数组和含大数组的结构体（>= sp-buffer-size）是最接近堆栈保护器的。
    * 小数组和含小数组的结构体（< sp-buffer-size）是第二接近堆栈保护器的。
    * 采取了它们的地址的变量是第三接近堆栈保护器的。

  这将覆盖 ssp 功能属性。

  如果一个函数，它有一个 sspstrong 属性被内联到一个不具有 sspstrong 属性的函数，那么最后得到的函数将具有 sspstrong 属性。

* uwtable

  该属性表明，被指定的ABI要求为这个函数展开表实体，即使我们可以表明没有异常会被这个函数传递。。这通常是针对于ELF x86-64 ABI的情况，但是它可以为某些编译单元被禁用。

* nocf_check

    This attribute indicates that no control-flow check will be performed on the attributed entity. It disables -fcf-protection=<> for a specific entity to fine grain the HW control flow protection mechanism. The flag is target independent and currently appertains to a function or function pointer.
* shadowcallstack

    This attribute indicates that the ShadowCallStack checks are enabled for the function. The instrumentation checks that the return address for the function has not changed between the function prolog and eiplog. It is currently x86_64-specific.

## 全局属性（Global Attributes）
Attributes may be set to communicate additional information about a global variable. Unlike function attributes, attributes on a global variable are grouped into a single attribute group.

## Operand Bundles
Operand bundles are tagged sets of SSA values that can be associated with certain LLVM instructions (currently only call s and invoke s). In a way they are like metadata, but dropping them is incorrect and will change program semantics.

Syntax:
```
operand bundle set ::= '[' operand bundle (, operand bundle )* ']'
operand bundle ::= tag '(' [ bundle operand ] (, bundle operand )* ')'
bundle operand ::= SSA value
tag ::= string constant
```
Operand bundles are not part of a function’s signature, and a given function may be called from multiple places with different kinds of operand bundles. This reflects the fact that the operand bundles are conceptually a part of the call (or invoke), not the callee being dispatched to.

Operand bundles are a generic mechanism intended to support runtime-introspection-like functionality for managed languages. While the exact semantics of an operand bundle depend on the bundle tag, there are certain limitations to how much the presence of an operand bundle can influence the semantics of a program. These restrictions are described as the semantics of an “unknown” operand bundle. As long as the behavior of an operand bundle is describable within these restrictions, LLVM does not need to have special knowledge of the operand bundle to not miscompile programs containing it.

  * The bundle operands for an unknown operand bundle escape in unknown ways before control is transferred to the callee or invokee.
  * Calls and invokes with operand bundles have unknown read / * write effect on the heap on entry and exit (even if the call target is readnone or readonly), unless they’re overridden with callsite specific attributes.
  * An operand bundle at a call site cannot change the implementation of the called function. Inter-procedural optimizations work as usual as long as they take into account the first two properties.

More specific types of operand bundles are described below.

### Deoptimization Operand Bundles
Deoptimization operand bundles are characterized by the "deopt" operand bundle tag. These operand bundles represent an alternate “safe” continuation for the call site they’re attached to, and can be used by a suitable runtime to deoptimize the compiled frame at the specified call site. There can be at most one "deopt" operand bundle attached to a call site. Exact details of deoptimization is out of scope for the language reference, but it usually involves rewriting a compiled frame into a set of interpreted frames.

From the compiler’s perspective, deoptimization operand bundles make the call sites they’re attached to at least readonly. They read through all of their pointer typed operands (even if they’re not otherwise escaped) and the entire visible heap. Deoptimization operand bundles do not capture their operands except during deoptimization, in which case control will not be returned to the compiled frame.

The inliner knows how to inline through calls that have deoptimization operand bundles. Just like inlining through a normal call site involves composing the normal and exceptional continuations, inlining through a call site with a deoptimization operand bundle needs to appropriately compose the “safe” deoptimization continuation. The inliner does this by prepending the parent’s deoptimization continuation to every deoptimization continuation in the inlined body. E.g. inlining @f into @g in the following example
```
define void @f() {
  call void @x()  ;; no deopt state
  call void @y() [ "deopt"(i32 10) ]
  call void @y() [ "deopt"(i32 10), "unknown"(i8* null) ]
  ret void
}

define void @g() {
  call void @f() [ "deopt"(i32 20) ]
  ret void
}
```
will result in
```
define void @g() {
  call void @x()  ;; still no deopt state
  call void @y() [ "deopt"(i32 20, i32 10) ]
  call void @y() [ "deopt"(i32 20, i32 10), "unknown"(i8* null) ]
  ret void
}
```
It is the frontend’s responsibility to structure or encode the deoptimization state in a way that syntactically prepending the caller’s deoptimization state to the callee’s deoptimization state is semantically equivalent to composing the caller’s deoptimization continuation after the callee’s deoptimization continuation.

### Funclet Operand Bundles
Funclet operand bundles are characterized by the "funclet" operand bundle tag. These operand bundles indicate that a call site is within a particular funclet. There can be at most one "funclet" operand bundle attached to a call site and it must have exactly one bundle operand.

If any funclet EH pads have been “entered” but not “exited” (per the description in the EH doc), it is undefined behavior to execute a call or invoke which:

  * does not have a "funclet" bundle and is not a call to a nounwind intrinsic, or
  * has a "funclet" bundle whose operand is not the most-recently-entered not-yet-exited funclet EH pad.

Similarly, if no funclet EH pads have been entered-but-not-yet-exited, executing a call or invoke with a "funclet" bundle is undefined behavior.


### GC Transition Operand Bundles
GC transition operand bundles are characterized by the "gc-transition" operand bundle tag. These operand bundles mark a call as a transition between a function with one GC strategy to a function with a different GC strategy. If coordinating the transition between GC strategies requires additional code generation at the call site, these bundles may contain any values that are needed by the generated code. For more details, see GC Transitions.

## 模块级别内联汇编
模块包含“module-level inline assembly”块，这与GCC中的“file scope inline asm”块的相同的。这些块将被LLVM内部链接并当作一个单独的单元，但如果希望的话，它们在.ll 文件中可以是分开的。它的语法十分简单：
```
module asm "inline asm code goes here"
module asm "more can go here"
```
这个字符串可以通过非输出字符转义包含任意字符。这个转义序列是“\xx”形式的，这个“xx”是两个十六位的数字。

当汇编代码生成时，这份内联汇编代码十分容易打印为机器代码 .s 文件

## 数据布局(Data Layout)
模块可以指定一个目标平台指定的数据布局的字符串，它指定数据在内存中是如何布局的。数据布局的语法很简单：
```
target datalayout = "layout specification"
```
布局规格由减号字符（' - '）分隔的列表组成 。每种规格以一个字母开头，并且可以包含在这个字母定义了某些方面的数据布局之后的其他星系。被接受的规格如下：

* E

    表明，目标平台在数据布局中使用big-endian格式。高字节在低地址，低字节在高地址。
* e

    表明，目标平台在数据布局中使用little-endian格式。低字节在低地址，高字节在高地址。

* `S<size>`

  指定堆栈中的bit的自然对齐。栈变量的对齐提升被限制到这个自然的栈对齐而避免动态栈重对齐。这个栈的对齐长度必须是8位的倍数。如果省略，自然栈对齐默认为“未指定” ，这并不妨碍任何对齐提升。

* `P<address space>`

    Specifies the address space that corresponds to program memory. Harvard architectures can use this to specify what space LLVM should place things such as functions into. If omitted, the program memory space defaults to the default address space of 0, which corresponds to a Von Neumann architecture that has code and data in the same space.

* `A<address space>`
    Specifies the address space of objects created by ‘alloca’. Defaults to the default address space of 0.

* `p[n]:<size>:<abi>:<pref>`

  这指定一个指针的大小和它对于地址空间 n 的<abi>和<pref>对齐误差。所有长度单位都为bit。这个地址空间，n 是可选的，如果未指定，则表示缺省地址空间0。n 的值必须在范围[1,2^23). 。
* `i<size>:<abi>:<pref>`

  这表明一个整数类型以bit <size>对齐， <size>的值必须为[1,2^23)
* `v<size>:<abi>:<pref>`

  这表明一个向量类型以bit <size>对齐。
* `f<size>:<abi>:<pref>`

  这表明一个浮点类型以bit <size>对齐。仅当<size>的值被目标平台支持才会工作。32（float）和64（double）被所有目标平台所支持。80 或 128(不同于long double)也被某些平台支持。
* `a:<abi>:<pref>`

  这表明对象集合类型的对齐。

* `F<type><abi>`

     This specifies the alignment for function pointers. The options for <type> are:

     * i: The alignment of function pointers is independent of the alignment of functions, and is a multiple of <abi>.
     * n: The alignment of function pointers is a multiple of the explicit alignment specified on the function, and is a multiple of <abi>.

* `m:<mangling>`

  如果这个属性存在，就表明了LLVM的名称将会在输出的时候被校正，有以下选项：
  * e: ELF校正：private 符号会带上一个 .L 前缀
  * m: Mips校正：private 符号会带上一个 $ 前缀
  * o: Mach-O校正：private 符号会带上一个 L 前缀。其他符号将带上一个 _ 前缀
  * w: Window COFF前缀：与Mach-O相似，但stdcall 与 fastcall 函数将会带有一个基于帧大小的后缀。

* `n<size1>:<size2>:<size3>...`

  这指明了目标平台的一个以bit为单位的本地整数宽度集。例如，对于32-bit PowerPC有 n32 ，对于PowerPC 64有 n32:64，或者对于X86-64有 n8:16:32:64。这个集合里的元素被认为是有效地支持最普遍的算术运算。

  在每一个带有 <abi>:<pref> 的标识中，指明 <pref> 对齐是可选的。如果 <pref> 被省略，那么这个冒号 ：也应该被省略，并且 <pref> 将与 <abi> 相等。

  当为一个给定的目标平台构造数据布局的时候，LLVM将会开始于一组默认标识的集合，但这组集合可以被 datalayout 关键字指明的标识重写。默认的标识将在以下这个列表中给定：
    * E - big endian
    * p:64:64:64 - 64bit的指针将有64bit的对齐。
    * p[n]:64:64:64 - 其他地址空间被认为与默认地址空间是相同。
    * S0 - 自然堆栈对齐是未指定的
    * i1:8:8 - i1 是8bit（byte）对齐的
    * i8:8:8 - i8 是8bit（byte）对齐的
    * i16:16:16 - i16 是16bit对齐的
    * i32:32:32 - i32 是32bit对齐的
    * i64:32:64 - i64 要求32bit的ABI对齐，但64bit对齐是更好的选择
    * f16:16:16 - half 是16bit对齐的
    * f32:32:32 - float 是32bit对齐的
    * f64:64:64 - double 是64bit对齐的
    * f128:128:128 - quad 是128bit对齐的
    * v64:64:64 - 64bit的vector是64bit对齐的
    * v128:128:128 - 128bit的vector是128bit对齐的
    * a:0:64 - 集合是64bit对齐的

当LLVM决定一个给定类型的对齐属性的时候，它将会使用以下规则：

  * 如果类型查找明确匹配到了这些标识的其中一个，这个标识将会被使用。
  * 如果没有找到匹配，并且这个类型查找确定是一个整数类型，那么将大于这个被使用的查找类型的位宽的最小整数类型将会被使用。如果这些标识中没有一个大于这个位宽，那么最大的整数类型将被使用，例如，给定上述的默认标识，i7类型将会使用i8（下一个最大值）的对齐属性，同样的i65和i256都将使用i64的对齐属性（可指定的最大值）。
  * 如果没有找到匹配，并且被查找的类型是一个vector类型，那么小于这个被查找的vector最大vector类型将会被用作回落。这是根据<128 x double>可以被64 <2 x double>的组合代替。

数据布局字符串的函数可能不是你所期望的。值得注意的是，这并不是说，指定代码生成器应使用的对齐属性的标识取决于前端代码。

相反，如果被指定，目标平台的数据布局将被要求匹配到最终的代码生成器所期望的形式。这个字符串是被用于mid-level优化器来提升代码的，并且只有这个字符串与最终的代码生成器所使用的形式相匹配时，这个字符串才会被使用。如果你想要生成IR，而不希望这些平台相关的细节嵌入到这个IR中，那么你不需要指定这个字符串。这将会禁用某些需要精确布局信息的优化，但这也防止这些优化插入这些平台相关的细节到IR中。

## Target Triple
A module may specify a target triple string that describes the target host. The syntax for the target triple is simply:
```
target triple = "x86_64-apple-macosx10.7.0"
```
The target triple string consists of a series of identifiers delimited by the minus sign character (‘-‘). The canonical forms are:
```
ARCHITECTURE-VENDOR-OPERATING_SYSTEM
ARCHITECTURE-VENDOR-OPERATING_SYSTEM-ENVIRONMENT
```
This information is passed along to the backend so that it generates code for the proper architecture. It’s possible to override this on the command line with the -mtriple command line option.

## Pointer Aliasing Rules
Any memory access must be done through a pointer value associated with an address range of the memory access, otherwise the behavior is undefined. Pointer values are associated with address ranges according to the following rules:

  * A pointer value is associated with the addresses associated with any value it is based on.
  * An address of a global variable is associated with the address range of the variable’s storage.
  * The result value of an allocation instruction is associated with the address range of the allocated storage.
  * A null pointer in the default address-space is associated with no address.
  * An integer constant other than zero or a pointer value returned from a function not defined within LLVM may be associated with address ranges allocated through mechanisms other than those provided by LLVM. Such ranges shall not overlap with any ranges of addresses allocated by mechanisms provided by LLVM.

A pointer value is based on another pointer value according to the following rules:

  * A pointer value formed from a scalar getelementptr operation is based on the pointer-typed operand of the getelementptr.
  * The pointer in lane l of the result of a vector getelementptr operation is based on the pointer in lane l of the vector-of-pointers-typed operand of the getelementptr.
  * The result value of a bitcast is based on the operand of the bitcast.
  * A pointer value formed by an inttoptr is based on all pointer values that contribute (directly or indirectly) to the computation of the pointer’s value.
  * The “based on” relationship is transitive.

Note that this definition of “based” is intentionally similar to the definition of “based” in C99, though it is slightly weaker.

LLVM IR does not associate types with memory. The result type of a load merely indicates the size and alignment of the memory from which to load, as well as the interpretation of the value. The first operand type of a store similarly only indicates the size and alignment of the store.

Consequently, type-based alias analysis, aka TBAA, aka -fstrict-aliasing, is not applicable to general unadorned LLVM IR. Metadata may be used to encode additional information which specialized optimization passes may use to implement type-based alias analysis.

## Volatile Memory Access
Certain memory accesses, such as load’s, store’s, and llvm.memcpy’s may be marked volatile. The optimizers must not change the number of volatile operations or change their order of execution relative to other volatile operations. The optimizers may change the order of volatile operations relative to non-volatile operations. This is not Java’s “volatile” and has no cross-thread synchronization behavior.

A volatile load or store may have additional target-specific semantics. Any volatile operation can have side effects, and any volatile operation can read and/or modify state which is not accessible via a regular load or store in this module. Volatile operations may use addresses which do not point to memory (like MMIO registers). This means the compiler may not use a volatile operation to prove a non-volatile access to that address has defined behavior.

The allowed side-effects for volatile accesses are limited. If a non-volatile store to a given address would be legal, a volatile operation may modify the memory at that address. A volatile operation may not modify any other memory accessible by the module being compiled. A volatile operation may not call any code in the current module.

The compiler may assume execution will continue after a volatile operation, so operations which modify memory or may have undefined behavior can be hoisted past a volatile operation.

IR-level volatile loads and stores cannot safely be optimized into llvm.memcpy or llvm.memmove intrinsics even when those intrinsics are flagged volatile. Likewise, the backend should never split or merge target-legal volatile load/store instructions.

Rationale

Platforms may rely on volatile loads and stores of natively supported data width to be executed as single instruction. For example, in C this holds for an l-value of volatile primitive type with native hardware support, but not necessarily for aggregate types. The frontend upholds these expectations, which are intentionally unspecified in the IR. The rules above ensure that IR transformations do not violate the frontend’s contract with the language.

## 并行操作的内存模型(Memory Model for Concurrent Operations)
The LLVM IR does not define any way to start parallel threads of execution or to register signal handlers. Nonetheless, there are platform-specific ways to create them, and we define LLVM IR’s behavior in their presence. This model is inspired by the C++0x memory model.

For a more informal introduction to this model, see the LLVM Atomic Instructions and Concurrency Guide.

We define a happens-before partial order as the least partial order that

  * Is a superset of single-thread program order, and
  * When a synchronizes-with b, includes an edge from a to b. Synchronizes-with pairs are introduced by platform-specific techniques, like pthread locks, thread creation, thread joining, etc., and by atomic instructions. (See also Atomic Memory Ordering Constraints).

Note that program order does not introduce happens-before edges between a thread and signals executing inside that thread.

Every (defined) read operation (load instructions, memcpy, atomic loads/read-modify-writes, etc.) R reads a series of bytes written by (defined) write operations (store instructions, atomic stores/read-modify-writes, memcpy, etc.). For the purposes of this section, initialized globals are considered to have a write of the initializer which is atomic and happens before any other read or write of the memory in question. For each byte of a read R, Rbyte may see any write to the same byte, except:

  * If write1 happens before write2, and write2 happens before Rbyte, then Rbyte does not see write1.
  * If Rbyte happens before write3, then Rbyte does not see write3.

Given that definition, Rbyte is defined as follows:

  * If R is volatile, the result is target-dependent. (Volatile is supposed to give guarantees which can support sig_atomic_t in C/C++, and may be used for accesses to addresses that do not behave like normal memory. It does not generally provide cross-thread synchronization.)
  * Otherwise, if there is no write to the same byte that happens before Rbyte, Rbyte returns undef for that byte.
  * Otherwise, if Rbyte may see exactly one write, Rbyte returns the value written by that write.
  * Otherwise, if R is atomic, and all the writes Rbyte may see are atomic, it chooses one of the values written. See the Atomic Memory Ordering Constraints section for additional constraints on how the choice is made.
  * Otherwise Rbyte returns undef.

R returns the value composed of the series of bytes it read. This implies that some bytes within the value may be undef without the entire value being undef. Note that this only defines the semantics of the operation; it doesn’t mean that targets will emit more than one instruction to read the series of bytes.

Note that in cases where none of the atomic intrinsics are used, this model places only one restriction on IR transformations on top of what is required for single-threaded execution: introducing a store to a byte which might not otherwise be stored is not allowed in general. (Specifically, in the case where another thread might write to and read from an address, introducing a store can change a load that may see exactly one write into a load that may see multiple writes.)
## Atomic Memory Ordering Constraints
Atomic instructions (cmpxchg, atomicrmw, fence, atomic load, and atomic store) take ordering parameters that determine which other atomic instructions on the same address they synchronize with. These semantics are borrowed from Java and C++0x, but are somewhat more colloquial. If these descriptions aren’t precise enough, check those specs (see spec references in the atomics guide). fence instructions treat these orderings somewhat differently since they don’t take an address. See that instruction’s documentation for details.

For a simpler introduction to the ordering constraints, see the LLVM Atomic Instructions and Concurrency Guide.

* unordered

    The set of values that can be read is governed by the happens-before partial order. A value cannot be read unless some operation wrote it. This is intended to provide a guarantee strong enough to model Java’s non-volatile shared variables. This ordering cannot be specified for read-modify-write operations; it is not strong enough to make them atomic in any interesting way.

* monotonic

    In addition to the guarantees of unordered, there is a single total order for modifications by monotonic operations on each address. All modification orders must be compatible with the happens-before order. There is no guarantee that the modification orders can be combined to a global total order for the whole program (and this often will not be possible). The read in an atomic read-modify-write operation (cmpxchg and atomicrmw) reads the value in the modification order immediately before the value it writes. If one atomic read happens before another atomic read of the same address, the later read must see the same value or a later value in the address’s modification order. This disallows reordering of monotonic (or stronger) operations on the same address. If an address is written monotonic-ally by one thread, and other threads monotonic-ally read that address repeatedly, the other threads must eventually see the write. This corresponds to the C++0x/C1x memory_order_relaxed.

* acquire

    In addition to the guarantees of monotonic, a synchronizes-with edge may be formed with a release operation. This is intended to model C++’s memory_order_acquire.

* release

    In addition to the guarantees of monotonic, if this operation writes a value which is subsequently read by an acquire operation, it synchronizes-with that operation. (This isn’t a complete description; see the C++0x definition of a release sequence.) This corresponds to the C++0x/C1x memory_order_release.

* acq_rel (acquire+release)

    Acts as both an acquire and release operation on its address. This corresponds to the C++0x/C1x memory_order_acq_rel.

* seq_cst (sequentially consistent)

    In addition to the guarantees of acq_rel (acquire for an operation that only reads, release for an operation that only writes), there is a global total order on all sequentially-consistent operations on all addresses, which is consistent with the happens-before partial order and with the modification orders of all the affected addresses. Each sequentially-consistent read sees the last preceding write to the same address in this global order. This corresponds to the C++0x/C1x memory_order_seq_cst and Java volatile.

If an atomic operation is marked syncscope("singlethread"), it only synchronizes with and only participates in the seq_cst total orderings of other operations running in the same thread (for example, in signal handlers).

If an atomic operation is marked syncscope("`<target-scope>`"), where `<target-scope>` is a target specific synchronization scope, then it is target dependent if it synchronizes with and participates in the seq_cst total orderings of other operations.

Otherwise, an atomic operation that is not marked syncscope("`singlethread`") or syncscope("`<target-scope>`") synchronizes with and participates in the seq_cst total orderings of other operations that are not marked syncscope("singlethread") or syncscope("`<target-scope>`").

## Floating-Point Environment
The default LLVM floating-point environment assumes that floating-point instructions do not have side effects. Results assume the round-to-nearest rounding mode. No floating-point exception state is maintained in this environment. Therefore, there is no attempt to create or preserve invalid operation (SNaN) or division-by-zero exceptions.

The benefit of this exception-free assumption is that floating-point operations may be speculated freely without any other fast-math relaxations to the floating-point model.

Code that requires different behavior than this should use the Constrained Floating-Point Intrinsics.

## Fast-Math Flags
LLVM IR floating-point operations (fadd, fsub, fmul, fdiv, frem, fcmp) and call may use the following flags to enable otherwise unsafe floating-point transformations.


* nnan

    No NaNs - Allow optimizations to assume the arguments and result are not NaN. If an argument is a nan, or the result would be a nan, it produces a poison value instead.

* ninf

    No Infs - Allow optimizations to assume the arguments and result are not +/-Inf. If an argument is +/-Inf, or the result would be +/-Inf, it produces a poison value instead.

* nsz

    No Signed Zeros - Allow optimizations to treat the sign of a zero argument or result as insignificant.

* arcp

    Allow Reciprocal - Allow optimizations to use the reciprocal of an argument rather than perform division.

* contract

    Allow floating-point contraction (e.g. fusing a multiply followed by an addition into a fused multiply-and-add).

* afn

    Approximate functions - Allow substitution of approximate calculations for functions (sin, log, sqrt, etc). See floating-point intrinsic definitions for places where this can apply to LLVM’s intrinsic math functions.

* reassoc

    Allow reassociation transformations for floating-point instructions. This may dramatically change results in floating-point.

* fast

    This flag implies all of the others.

## Use-list Order Directives
Use-list directives encode the in-memory order of each use-list, allowing the order to be recreated. <order-indexes> is a comma-separated list of indexes that are assigned to the referenced value’s uses. The referenced value’s use-list is immediately sorted by these indexes.

Use-list directives may appear at function scope or global scope. They are not instructions, and have no effect on the semantics of the IR. When they’re at function scope, they must appear after the terminator of the final basic block.

If basic blocks have their address taken via blockaddress() expressions, uselistorder_bb can be used to reorder their use-lists from outside their function’s scope.
Syntax:
```
uselistorder <ty> <value>, { <order-indexes> }
uselistorder_bb @function, %block { <order-indexes> }
```
Examples:
```
define void @foo(i32 %arg1, i32 %arg2) {
entry:
  ; ... instructions ...
bb:
  ; ... instructions ...

  ; At function scope.
  uselistorder i32 %arg1, { 1, 0, 2 }
  uselistorder label %bb, { 1, 0 }
}

; At global scope.
uselistorder i32* @global, { 1, 2, 0 }
uselistorder i32 7, { 1, 0 }
uselistorder i32 (i32) @bar, { 1, 0 }
uselistorder_bb @foo, %bb, { 5, 1, 3, 2, 0, 4 }
```

## Source Filename
The source filename string is set to the original module identifier, which will be the name of the compiled source file when compiling from source through the clang front end, for example. It is then preserved through the IR and bitcode.

This is currently necessary to generate a consistent unique global identifier for local functions used in profile data, which prepends the source file name to the local function name.

The syntax for the source file name is simply:
```
source_filename = "/path/to/source.c"
```
